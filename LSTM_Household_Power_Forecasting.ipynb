{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Forecasting for Household Power Consumption\n",
    "## Energy Consumption Optimization using Deep Learning\n",
    "\n",
    "This notebook builds an LSTM model to forecast household power consumption for optimizing energy usage in buildings and homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the household power consumption dataset\n",
    "df = pd.read_csv('household_power_consumption.txt', sep=';', low_memory=False)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN and convert to numeric\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Convert columns to numeric\n",
    "for col in df.columns[2:]:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Handle missing values - forward fill then backward fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Create datetime column\n",
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "df.set_index('DateTime', inplace=True)\n",
    "df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Data after preprocessing:\")\n",
    "print(df.head())\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nMissing values after preprocessing:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Global Active Power as the target variable\n",
    "data = df[['Global_active_power']].values\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(data, linewidth=0.5)\n",
    "plt.title('Household Global Active Power Consumption Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Data statistics:\")\n",
    "print(f\"Mean: {data.mean():.2f} kW\")\n",
    "print(f\"Std: {data.std():.2f} kW\")\n",
    "print(f\"Min: {data.min():.2f} kW\")\n",
    "print(f\"Max: {data.max():.2f} kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(f\"Scaled data shape: {scaled_data.shape}\")\n",
    "print(f\"Scaled data range: [{scaled_data.min():.4f}, {scaled_data.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences with lookback window of 60 time steps\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Split into train and test sets (80-20 split)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(seq_length, 1), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(25, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('Model Loss', fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history.history['mae'], label='Training MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "axes[1].set_title('Model MAE', fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform to get actual values\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_actual = scaler.inverse_transform(y_pred)\n",
    "\n",
    "print(f\"Predictions shape: {y_pred_actual.shape}\")\n",
    "print(f\"First 10 predictions: {y_pred_actual[:10].flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f} kW\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f} kW\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_actual, label='Actual', linewidth=2)\n",
    "plt.plot(y_pred_actual, label='Predicted', linewidth=2, alpha=0.7)\n",
    "plt.title('Actual vs Predicted Power Consumption', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot zoomed view\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_actual[:500], label='Actual', linewidth=2)\n",
    "plt.plot(y_pred_actual[:500], label='Predicted', linewidth=2, alpha=0.7)\n",
    "plt.title('Actual vs Predicted Power Consumption (First 500 samples)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "model.save('lstm_power_model.h5')\n",
    "print(\"Model saved as 'lstm_power_model.h5'\")\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Scaler saved as 'scaler.pkl'\")\n",
    "\n",
    "# Save sequence length for reference\n",
    "with open('seq_length.pkl', 'wb') as f:\n",
    "    pickle.dump(seq_length, f)\n",
    "print(\"Sequence length saved as 'seq_length.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Energy Optimization Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy optimization metrics\n",
    "avg_consumption = y_test_actual.mean()\n",
    "peak_consumption = y_test_actual.max()\n",
    "low_consumption = y_test_actual.min()\n",
    "\n",
    "print(\"\\n=== ENERGY CONSUMPTION ANALYSIS ===\")\n",
    "print(f\"Average Power Consumption: {avg_consumption:.2f} kW\")\n",
    "print(f\"Peak Power Consumption: {peak_consumption:.2f} kW\")\n",
    "print(f\"Minimum Power Consumption: {low_consumption:.2f} kW\")\n",
    "print(f\"Peak-to-Average Ratio: {peak_consumption/avg_consumption:.2f}x\")\n",
    "\n",
    "# Identify high consumption periods\n",
    "high_threshold = avg_consumption * 1.5\n",
    "high_periods = (y_test_actual > high_threshold).sum()\n",
    "print(f\"\\nHigh consumption periods (>1.5x average): {high_periods} out of {len(y_test_actual)} ({high_periods/len(y_test_actual)*100:.1f}%)\")\n",
    "\n",
    "# Prediction error analysis\n",
    "errors = np.abs(y_test_actual - y_pred_actual)\n",
    "print(f\"\\n=== PREDICTION ACCURACY ===\")\n",
    "print(f\"Mean Absolute Error: {errors.mean():.4f} kW\")\n",
    "print(f\"Max Error: {errors.max():.4f} kW\")\n",
    "print(f\"Error Std Dev: {errors.std():.4f} kW\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
